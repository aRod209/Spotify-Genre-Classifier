{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_pytorch_transfer_learning_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aRod209/Spotify-Genre-Classifier/blob/main/exercises/06_pytorch_transfer_learning_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 06. PyTorch Transfer Learning Exercises\n",
        "\n",
        "Welcome to the 06. PyTorch Transfer Learning exercise template notebook.\n",
        "\n",
        "There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.\n",
        "\n",
        "> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can.\n",
        "\n",
        "## Resources and solutions\n",
        "\n",
        "* These exercises/solutions are based on [section 06. PyTorch Transfer Learning](https://www.learnpytorch.io/06_pytorch_transfer_learning/) of the Learn PyTorch for Deep Learning course by Zero to Mastery.\n",
        "\n",
        "**Solutions:**\n",
        "\n",
        "Try to complete the code below *before* looking at these.\n",
        "\n",
        "* See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/ueLolShyFqs).\n",
        "* See an example [solutions notebook for these exercises on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/06_pytorch_transfer_learning_exercise_solutions.ipynb)."
      ],
      "metadata": {
        "id": "zNqPNlYylluR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Make predictions on the entire test dataset and plot a confusion matrix for the results of our model compared to the truth labels.\n",
        "* **Note:** You will need to get the dataset and the trained model/retrain the model from notebook 06 to perform predictions.\n",
        "* Check out [03. PyTorch Computer Vision section 10](https://www.learnpytorch.io/03_pytorch_computer_vision/#10-making-a-confusion-matrix-for-further-prediction-evaluation) for ideas."
      ],
      "metadata": {
        "id": "nwmoMhW8IqSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries/code\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "nqtAWBUJgaF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "O10_T_xSKJlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data"
      ],
      "metadata": {
        "id": "nrzg3TaSKLAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi data...\")\n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "id": "Lt_CNQ4rKPmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare data"
      ],
      "metadata": {
        "id": "PGaMWWaoKQlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a transforms pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ],
      "metadata": {
        "id": "VNIQNEQVKVXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "Njd5lHTcKW23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get and prepare a pretrained model"
      ],
      "metadata": {
        "id": "Ciw2DiRHKaSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the model with pretrained weights and send it to the target device\n",
        "model_0 = torchvision.models.efficientnet_b0(pretrained=True).to(device)\n",
        "#model_0 # uncomment to output (it's very long)"
      ],
      "metadata": {
        "id": "snUuRXd8Kdk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model_0.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "IbRhGvy_KeVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Get the length of class_names (one output unit for each class)\n",
        "output_shape = len(class_names)\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model_0.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1280,\n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)"
      ],
      "metadata": {
        "id": "G1-6xV3ZKeSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "XQFaXX8CKePi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "exxU79eaKeM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "model_0_results = engine.train(model=model_0,\n",
        "                       train_dataloader=train_dataloader,\n",
        "                       test_dataloader=test_dataloader,\n",
        "                       optimizer=optimizer,\n",
        "                       loss_fn=loss_fn,\n",
        "                       epochs=5,\n",
        "                       device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "ComVkVtuKeKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make predictions on the entire test dataset with the model"
      ],
      "metadata": {
        "id": "xFS4lE_IKyE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_labels = []\n",
        "\n",
        "# Put model in eval mode\n",
        "model_0.eval()\n",
        "\n",
        "# Turn on inference context manager\n",
        "with torch.inference_mode():\n",
        "  # Loop through DataLoader batches\n",
        "  for batch, (X, y) in enumerate(test_dataloader):\n",
        "    # Send data to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    test_pred_logits = model_0(X)\n",
        "\n",
        "    # 2. Get predicted target labels\n",
        "    test_pred_labels.append(test_pred_logits.argmax(dim=1))\n",
        "\n",
        "test_pred_labels[:5]"
      ],
      "metadata": {
        "id": "DwZuCluFu375"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a confusion matrix with the test preds and the truth labels"
      ],
      "metadata": {
        "id": "Mb2bQ1b5K2WP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need the following libraries to make a confusion matrix:\n",
        "* torchmetrics - https://torchmetrics.readthedocs.io/en/stable/\n",
        "* mlxtend - http://rasbt.github.io/mlxtend/"
      ],
      "metadata": {
        "id": "5I2jpYAcM07s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
        "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
        "except:\n",
        "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
        "    import torchmetrics, mlxtend\n",
        "    print(f\"mlxtend version: {mlxtend.__version__}\")"
      ],
      "metadata": {
        "id": "qcKYZGWuK2P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mlxtend upgraded version\n",
        "import mlxtend\n",
        "print(mlxtend.__version__)\n",
        "assert int(mlxtend.__version__.split(\".\")[1]) >= 19 # should be version 0.19.0 or higher"
      ],
      "metadata": {
        "id": "QOYVew4xMxgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "_5LU9-5Xu7dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Get the \"most wrong\" of the predictions on the test dataset and plot the 5 \"most wrong\" images. You can do this by:\n",
        "* Predicting across all of the test dataset, storing the labels and predicted probabilities.\n",
        "* Sort the predictions by *wrong prediction* and then *descending predicted probabilities*, this will give you the wrong predictions with the *highest* prediction probabilities, in other words, the \"most wrong\".\n",
        "* Plot the top 5 \"most wrong\" images, why do you think the model got these wrong?\n",
        "\n",
        "You'll want to:\n",
        "* Create a DataFrame with sample, label, prediction, pred prob\n",
        "* Sort DataFrame by correct (does label == prediction)\n",
        "* Sort DataFrame by pred prob (descending)\n",
        "* Plot the top 5 \"most wrong\" image predictions"
      ],
      "metadata": {
        "id": "YqlStPo-gbrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "cHtMeYHuvDwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Predict on your own image of pizza/steak/sushi - how does the model go? What happens if you predict on an image that isn't pizza/steak/sushi?\n",
        "* Here you can get an image from a website like http://www.unsplash.com to try it out or you can upload your own."
      ],
      "metadata": {
        "id": "1IvuTskxgjaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Get an image of pizza/steak/sushi\n"
      ],
      "metadata": {
        "id": "C16glgVFglmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Get an image of not pizza/steak/sushi\n"
      ],
      "metadata": {
        "id": "clA_KmihVYyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train the model from section 4  in notebook 06 part 3 for longer (10 epochs should do), what happens to the performance?\n",
        "\n",
        "* See the model in notebook 06 part 3 for reference: https://www.learnpytorch.io/06_pytorch_transfer_learning/#3-getting-a-pretrained-model"
      ],
      "metadata": {
        "id": "Vzvi8GprgmJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Recreate a new model\n"
      ],
      "metadata": {
        "id": "kIKg53Jna-Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train the model for 10 epochs"
      ],
      "metadata": {
        "id": "JhGT9igPgoF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train the model from section 4 above with more data, say 20% of the images from Food101 of Pizza, Steak and Sushi images.\n",
        "* You can find the [20% Pizza, Steak, Sushi dataset](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip) on the course GitHub. It was created with the notebook [`extras/04_custom_data_creation.ipynb`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb).\n"
      ],
      "metadata": {
        "id": "_oRrWPZTgoqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get 20% data"
      ],
      "metadata": {
        "id": "VxyMMnUbgvw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
        "image_data_zip_path = \"pizza_steak_sushi_20_percent.zip\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / image_data_zip_path, \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
        "        print(\"Downloading pizza, steak, sushi data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / image_data_zip_path, \"r\") as zip_ref:\n",
        "        print(\"Unzipping pizza, steak, sushi 20% data...\")\n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / image_data_zip_path)\n",
        "\n",
        "# Setup Dirs\n",
        "train_dir_20_percent = image_path / \"train\"\n",
        "test_dir_20_percent = image_path / \"test\"\n",
        "\n",
        "train_dir_20_percent, test_dir_20_percent"
      ],
      "metadata": {
        "id": "U_fdu5m2eKT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create DataLoaders"
      ],
      "metadata": {
        "id": "SQj7eFdSe4Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a transforms pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ],
      "metadata": {
        "id": "TEG_k785e7Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing DataLoader's as well as get a list of class names\n",
        "train_dataloader_20_percent, test_dataloader_20_percent, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
        "                                                                                                     test_dir=test_dir_20_percent,\n",
        "                                                                                                     transform=simple_transform, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                                                     batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader_20_percent, test_dataloader_20_percent, class_names"
      ],
      "metadata": {
        "id": "82x7LnQJe7H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get a pretrained model"
      ],
      "metadata": {
        "id": "qROl77sKfIOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "PHWNZ6yDvpR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a model with 20% of the data"
      ],
      "metadata": {
        "id": "UqffJfOIfp3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "wXpYOYeTvp7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Try a different model from [`torchvision.models`](https://pytorch.org/vision/stable/models.html) on the Pizza, Steak, Sushi data, how does this model perform?\n",
        "* You'll have to change the size of the classifier layer to suit our problem.\n",
        "* You may want to try an EfficientNet with a higher number than our B0, perhaps `torchvision.models.efficientnet_b2()`?\n",
        "  * **Note:** Depending on the model you use you will have to prepare/transform the data in a certain way."
      ],
      "metadata": {
        "id": "Ibj4UPjRgvly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "3FQ8tL7El7eO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}